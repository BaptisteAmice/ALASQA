//todo option télécharger log conversation
se concentrer sur l'extraction
//todo réessayer en listant les commandes
//todo evoquer spaklis, donner structure model et langage des commandes
    // a qq ; has ...; is ... of ... ; ...    
#todo ce qu'on attend c'ets les requetes, mais ce qu'on veut comparer ces les résultats pour une mm version
#type

//todo trouver comment automatiser test ET englobe rca dans API

//todo div llm target -> transform ou active qd extension active
____________
Jeux de données

base entrainement et evaluation
WIKIDATA
https://github.com/KGQA/QALD-10 -> ~80% pour etre significatif
https://github.com/amazon-science/mintaka
https://query.wikidata.org/


--
Sparklis LLM
dossier webapp (dans doc -> api js)
Importer script "extension" dans js + ajouter dans html -> éventuellement en script

demander plan de base -> essayer pour guider de base 
comparer 2 stratégies simples
-? construire directement suite commande en input utilisant qa_extension
-? choix mot de départ -> filtre et cherche dans les deux listes (pas de rep demande synonyme)-> lecture retour fr + rep -> doit continuer ? -> si oui filtre et recherche dans les deux listes -> etc 


-----------------------------------
TEXT2SPARQL workshop
https://text2sparql.aksw.org/#knowledge-graphs-for-evaluation